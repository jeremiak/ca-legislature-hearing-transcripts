ahead and get started- let me call the order the Senate select committee on the growing impact of artificial intelligence in California. Today's hearing is focused on applications and impacts for law enforcement in criminal justice and we're also pleased to help up the presiding judge the Orange County Superior Court here judge not camara exit talk a little bit about other interests with respect to artificial intelligence- we have here councilmember Jordan brand men and account number brand along of the- some women number X. office. Councilmember Brandon a direct. Thank you. Anaheim sport here in assisting us with this. Just so all of you know- this is being live streamed up throughout up to the Kaplan throughout the state M. I'm sure that there are millions and millions watching some just letting you know that before you you testified that we're competing with the impeachment hearings and I'm I'm sure many are just switching back and forth. So. Councilmember Benjamin thank you for being here. Thank you Mister chairman and good morning everyone welcome to the city of Anaheim first off and one I think a select committee chair senator Tom Umberg and the select committee members for bringing this important discussion to our city and allowing our community. The opportunity to be part of this dialogue California is the birthplace of some of our nation's greatest technological advances and I am glad to see that our leaders have acknowledged this and are taking steps your research and determine the best practices for working with ever changing medium. Our justice system. Access data and technological tools is greater than ever before. Law enforcement's ability to access this continues to grow. It is important that we are mindful of this and how these new mediums can positively impact the ability of law enforcement to uphold the law while also being respectful of our residents right to privacy. I am encouraged Mister chairman by today's meeting of our state leaders and I know California is well on its way tackling these important questions thank you again for allowing me to welcome you to our city. And for us to host you to. Thank you cal men and that. Then of making this hearing possible I want to thank also the staff that's here- both my staff sue Chang staff in other staff from Sacramento it it is a- an operation to hold a hearing sort of off campus and I'm grateful for all of you for assisting. Assess thank you Senate opening Chang is here with us today member the select committee. Appreciate your support pressure you being here- let me just make a few opening remarks a maternal over to senator Chang- today we're gonna be discussing current and future impact of artificial intelligence on federal state and local law enforcement as it relates to- possible predictive policing- and policies. As well as current future uses of our intelligence in the judicial system as it relates to criminal justice and the administration of justice with us here today. Retired special agent Claude Arnold from home and security investigations. Thank you Mister Arnold for being here also- surgeon Krister McDonald Orange County sheriff's department crime analysis unit. Thank you Sir Jim McDonald- the presiding judge the Orange County Superior Court judge Kirk not camara. Judge we're grateful for your presence as well- and- former state senator Joe don who's hiding- all over in the first- so to speak. Senator done here is gonna talk is special currently special adviser. To the dean at UCLA law school about of initiative at UC law school to advance our social intelligence you're in California. I won't turn over now to Senate change if you've got any opening remarks searching. Absolutely thank you. Thank you so much C. chairman number for convening this hearing I'm really excited to be here and I'm glad that he was able to work with the two days in our on our schedule- I am also a founding member of the tech innovation caucus so truly is an honor for me here- I am excited that artificial intelligence is getting so much attention in the legislature and that we do have a clearing house for information in hearings. This newly formed come. Yeah changing everything we do and we have to pay attention. Today we'll hear about law enforcement but a I also transforming the landscape of transportation healthcare. And how governments function. I authored legislation this year after year as did other members of the legislature to leverage a I. for the benefit of state government and bill protections against. Potential harms a I create. The governor made clear this year he wants little legislative regulation around the space at least for now. He believes his the he is the work Michigan is joining inception to tackle the challenges ahead of us so I hope that's true but I tend to believe we will need to solidify and copy protection. Around it in the coming years it's clear their husband. Is with. Buy low and for and it is our job to make sure the benefits are not drowned out. These negative consequences like proliferating bias through a I. job reduction in breaching privacy. I'm excited to hear from testimony. The committee has brought together some very exciting experts so thank you so much for being here and I look for to our conversation. Thank you. Thank you Sir John- we are going to have a public comment after we have the panelists- testify in and respond to some of our enquiries- we may have depend upon the number of folks who want to provide public comment- we may. Have to limit it to number of minutes we'll we'll take that this. Later on so let let let us begin first of let me call up. Recent retired special agent in charge of security investigations here in Los Angeles- special agent Claude Arnold special agent Arnold of first let me begin with the politically incorrect comic you look way too young to been retired but- so. Been retired for four years after serving for twenty seven years okay well listen up double down on the counter so. Much for having me US senators on Bergen Chang- happy here to speak to the committee a little bit about- my experience and understanding- with the use of artificial intelligence federally. And specifically with of my former agency- homeland security investigations which is a component of US immigration and customs enforcement. I'll say at the outset that I am not an artificial intelligence expert. So you know I can share my experiences but I certainly don't understand technically how works I know how to strategically and tactically and I'm gonna give some examples this morning. Of how that is done. How would it's been very effective as I've experience throughout my career so I served a brief background on myself I ice last served as a special agent in charge for almond security investigations here in Los Angeles for the last for five years until my retirement at the end of twenty fifteen. Prior to that I was especially been in charge in a Minneapolis Minnesota and I area of responsibility was a five state region there in the Midwest- I served in senior positions in headquarters and then you know my career it is with us fads I. Across the U. S. as I promoted transferred Midwest south west east coast. So yeah you know artificial intelligence but by definition it's just the development of computer systems are able to perform tasks that normally require human intelligence it you know in its simplest form a one example that I like to cite an an early example of artificial intelligence is license plate readers so- probably in the nineties- mid to late nineties the federal government started using the license plate read. That automatically a recorded license plates and then ran those license placed against various federal and other databases to identify potential violations of law. You know in in my- world we used it to identify drug smugglers- human traffickers. People involved in with in crime with the nexus to the border. So even though you know someone at near or in quarters at or near the ports of entry- license would be license plates would be recorded and then they would be run across databases okay this person may be headed south they're connected to a case this vehicle with drug smuggling and they may have. B. smuggling money southbound so when they the port of entry- you we wanted we want to do a border search on that vehicle or maybe we want the border patrol over or in one of our local because they make. Going proceeds extra. But or weapons thing like. So that that's an early example of artificial intelligence- but you know. Artificial intelligence is you several ways and law enforcement it can be used for crime analysis so. Cried and analysis geographic Belle says. Data analysis- network analysis tell of on a record analysis you know good example of this is- phone link analysis and this is something that started probably in the late eighties early nineties where in connection with an investigation you have a bunch of phone numbers either connected to a- an intercept of phone intercept court ordered phone intercepts or or just a- pen registers what we call it just recording phone numbers from people who you think are involved in criminal activity. Well you link these phone numbers to kind of create a picture of what the criminal activity is and who the players are in the criminal activity very early example of using a computer software to do the linkage instead of doing it on a white board. It's a lot more. At the end another great example of artificial intelligence that that is an early example is strategic analysis- so. You know this is strategic targeting for example I think one of the best examples of this is Los Angeles police department's compstat a lot of departments and agencies have employed that. That strategy and that's where you use. Computers to compile crime statistics. Identify potential threat areas so that you can dedicate resources. Areas where there's an emerging from all threats. So I a you know given some examples of. Early artificial intelligence I want to give you a couple more examples. So get out of bases another one and early on in my career I was assigned to the violent gang task force. The day cold a lot of data about. Many documented gang members and they allow investigators to make connections when there's a crime between people identify potential suspects they have bio metrics in them photographs- and where there's photo recognition capability- you can identify suspects through a photo so- I can give an example where I was. Inducting investigation of taking case this was in the nineties and I was in Phoenix Arizona agent and this was ground zero for- human smuggling and trafficking in the whole U. S. and so street gangs were- engaging and hostage taking taking people hostage. And then they could hold them for their human smuggling fee that still M. from human smuggling organizations. With guns in their be shoot outs on our people caught in the middle people get murdered at center was horrible- but so I had a case where street gang head- head of doc did a group of Ecuadorian nationals who had been smuggled into the U. S. at gun point. And when we can get a search warrant locate. We a photograph of a person bill didn't know who they were this is ninety two thousand so the technology even existed them. But of the Phoenix police department at the time was using photo recognition software and we're able to run that through their databases and we were able to identify one of the gang members who was involved. By this photograph who previously was not identified. So that's another early example of. Artificial intelligence so how does- H. a sigh use- artificial intelligence now well. Probably the biggest way of that not only H. aside but all federal agencies use artificial intelligence is through the compilation of disparate data right so there's many databases both federal and public database. That have a lot of information. But they're separate databases and so in the old days- an investigator. Who that was investigating let's say a specific individual as part of an organization whatever they would have to go run this person in this database on the person this database or you know to try and find out as much information about that target or even organization. And that take time and then that person so would have trying to establish connections between multiple subjects of say a criminal organization. From all these disparate data I mean you can see how that is very time consuming labor intensive and requires quite frankly. The limitations of the investigator that the human being. So now what's that there's these their systems that you know so all this data is for and again I'm not computer scientist I'm not in a I. expert but- basically all this data. Is put into a central location and there's a system that. Compiles at all and makes connections linkages you know the proverbial six degrees of separation- and that so this can be used and criminal investigations in terrorism investigations. In child exploitation investigations etcetera so bad is. Probably currently how artificial intelligence. Currently is most used by both homeland security investigations and other federal agents. A couple examples- so after right after nine eleven I know H. a site. Developed you know through contractors obviously a system that did Josh this and the purpose of it was specifically for. To contribute to terrorism investigations and terrorism travel right because DHS has data on how people travel but then you take other data and you make you know suspected terrorists the different watch lists. And travel patterns et cetera and you you can make these. Connections to people where the human being in human investigator might not have made that connection because there are several degrees of separation but now with the use of artificial intelligence and these are computer programs that can be done and you can identify a potential threat. Whereas previously that threat may not have been identified it's also used for example child X. Isshin investigations- there are certain. First of all I you know H. a size of federal agency that probably conducts more child **** and child exploitation destinations than any other federal agency so- they become very adept at doing so and leveraging technology to facilitate that so for example. You know child sex tourism it's a federal violation to travel internationally obviously. To go foreign and engaging in sex act with with a child a but it's a problem so how how do you solve this problem well. You can use our an artificial intelligence is used to look at people registered sex offenders at center all this data from disparate databases travel patterns to identify potential threats who may be traveling. To engage in child sex tourism. So that of foreign governments can be notified. And perhaps prevent- a child being victimized and it happens all the time ice has a program called angel watch and they just opened the center. It ribbon cutting last week and it's multiple federal agencies and that the purpose is just that to identify people who they're intent may be to travel to engage in child sex tourism and hopefully. Prevent that from happening. Another examples financial investigations every agency not just federal agents every agency. That conducts criminal designations has a component of which is a financial investigation follow the money so again it would require an investigator and analysts to go through lots of different data things and try and make a connection whereas using artificial intelligence computer programs. You can. Detect anomalies in financial activity- for example structuring right someone making deposits repetitively just under the federal reporting requirement of ten thousand dollars- if you have computer systems doing that. You can identify a pattern of potential criminal behavior and identify a larger criminal organization. I think that. In the future going forward. What one of the best applications for artificial intelligence is that. What the nine eleven commission. One of the recommendations was to unify the many participants in the counterterrorism effort and their knowledge and their knowledge in a network based information stern system that transcends traditional government boundaries because what we learned after nine eleven we learn that. Even federal agencies work talk you know these turf battles certainly they were sharing information with state and local governments and we found that that still has been a problem I that will that will. That that may have. The Boston Marathon bombing right. It it's all due to a lack of sharing of information so. Artificial intelligence can occur bush. Is our facilitate making these connections and sharing his informations across jurisdictional boundaries right and that would protect us all from- potential public safety or national security threats course. The big thing is it has to be done within the legal framework and in a way. That that doesn't violate people's privacy rights. I hope I didn't. Go over thank you no thank you special agent Arnold- before you with homeland security what agency were you with. So my career started with the I. N. S. yeah. In this is something I'm gonna hope I can perhaps tap into each of the experts here with respect artificial. All of the concerns with our intelligence is that it such that it actually replaces human beings in terms of decision making and what the implications are whether that that there is some sort of implicit bias for example that's incorporated into whatever design. Is created to have that algorithm actually make decisions so for example decisions as to where resources should be decisions as to- for example who should be who should be a fight as a suspect- one of the issues that we're faced is facial recognition technology in Sacramento. So in terms of the future- special Arnold are there any concerns that you have about the future of artificial legends and how it may at the river. Either humans into decision making or how there may be some sort of implicit bias that that may lead to stone- pass the two questions. Yes so I don't think you ever be able to remove the human element from the decision making. Process whether on the macro or or micro level so for example just on the investigator level you may have one of these systems. Create some language linkages and identify potential- a potential target and maybe someone who's involved in criminal activity but then that person is still going to have to present that case to a local prosecutor they're still going to have to. You know on an affidavit articulate probable cause for some of legal action against a target you a I will ever be able to do that for the person they're not gonna be able just to swap out an affidavit from front. Page so. I'm I think that. Now could still be misused. Yeah but but anyone Forsman tool or any law enforcement authority can be abused and misused so it's a incumbent upon law enforcement agencies to have policies in place. You know M. most of them already do- that that when authority is abuse or misuse that- people are disciplined and- you know so others are deterred from doing that as well I think that the in the future- artificial intelligence actually could create the affidavit obviously you can M. machine swear to it but actually could created. An affidavit to be submitted to a judge shouldn't one would hope that the Jeff is not a computer- but the anyway that that that's a concern so thank you- Senate check if questions. Comments. We're talking about homeland security I have a really quick question- are you aware of how a I've been using immigration and refugee. With Roth G. system if. There's any currently. Well the refugee system is at and the G. to catia refugee applications is not done by my former agency. You know violations of the law relating to that are investigated by my former agency so yeah I'm not aware of. Any he- current application of a I. in relation to the refugee system. Thank you US special agent Arnold let's now turn to US Surgeon McDonald and certainly bottled up would ask you some of the same questions- I do think that in the future that- there will be the creation of affidavits I think that in terms of judiciary there probably will be program lease that that they can be. They can be braided or that those affidavits to be plugged in. And analysis as to whether or not there is. Probable cause such that that I the machine can machine maybe. Not the right term but that the system can't can generate an answer or deficiencies- that that may exist. In Andy affidavits- so let me turn to sergeant McDonald serving Donald. Thank you here's. So first of all thank you very much for having me today I really appreciate- taking the time to listen to Mike to kind of my incite over I can provide that to you. A little bit as to how we're at on the state local side- it's just a little bit about me I come from a little bit of a bit different background- I work for the Orange County sheriff's department. Been there twenty years now. And I've had my range of experience Lara forced starting in the John working patrol and after I went to a- she went. To work with the joint person task force with the FBI so. The topics are in talk about I have experience on the federal side as well working through Faiza data and that larger. Data collection if you will- and then more recently I was promoted sergeant- and put in charge of a crime analysis detail so now I'm looking at- the difference our collection systems- different data collection that we have and how. To apply that not necessarily to national security or counterintelligence. Threat but more so on the local a crime level looking at solving a soldier or perhaps. So. My despair back a little bit about personally for me though I'm a very private person- Leyva live streaming this for me is a good step in the- you know like. Hello world I'm here I'm definitely not on social media at this there are people are you right exactly yeah well you're welcome that's the thermic right. So you know you will not find online at a lot of. Measures in my personal life to remove myself. From that kind digital footprint if you will. First because of my previous assignment I didn't want anybody else knowing where I lived or what I did. So I'm- I'm kind of in a in a unique situation that. Here I am trying to find clues that people left but at the same time remove myself from those very same system I used. To find people soft right. Sir a little bit different let me. And as I go through this hopefully I'll give you a good pictures to what we're using currently in I. a I and we're we're kind of I think we're headed and then probably some concerns that I have on that I'm really private side- so currently at in a minute Nancy and at my local you know. Southern California peer agency. Probably the away is- government data solutions is typically pretty slow to develop and evolve and I think we're really struggling even in my own agency to come up with data real time little on predictive- it- now looking at our our crime analysis unit and what it is that we're doing the steps that were king I think we're getting a lot closer to get. Real time data. I will visit department recently went paperless with the reporting. Five years ago- so if you look at how it is we're we're coming along there's a lot to take in a in a very short amount of time and I think that you know as we look at it and implementing these new. Data forms would really need to take a good strategic look and see where we want to be and how is it we want to use this data and for. Future growth so. Currently in NY who kind of sphere of influence that the systems that we're using right now. Are predominately facial recognition- I will tell you that- you know the systems that we use are. Are reactive it's not like we have a passive system. I. with government counters cameras mounted up places actively. Getting you know photographs of everybody in in the community. It's typically we have our our data set of photographs we have from jail booking photos or things like that. And compare it with. Hey we have crime we have this you know ring. Bell or you have. You know stores CZ. Camera we have a still image of that. Roth that was reference. What are known suspect please. Yeah Joel book yes. A lot of predictive analysis yet. The recognition- you know I could see at some point you know it in twenty thirty years from now you have a camera mounted and you have photographs of everybody that has an active warrant and it automatically scans the entire community. Points the people elected boards I don't I don't think we're definitely not there now and I don't think we would get there in the future as well I think that's a little too. A public consumption- and what we- and I think that I would leave that up to you guys to. Kind of stick a strategic look and see how that. How that's going to vault over time. So a couple other kind of points to make it in in some kind of the A. I. F. today what we're talking about my colleague mentioned- the license plate reader systems such more on that a little bit- I think that's probably the most tolerated because it's not so portion of personal it's your vehicle's not necessarily your face. That's being recorded. Sometimes as offer a lot of data and you do have you're the concerns of how long to be all that data and or we using that data on the back and right and currently it's not. A predictive measure it's not like we're tracking license plates and saying that they're going to particular place to commit a crime we're not having that. You know predictive alert system. It's more reactionary on the investigative side. Is Hey we saw this vehicle how is it that maybe that license plate was in the area at the time. Makes sense so. Actually the current- a I. that's most prevalent I think it's being I don't it's- in the commercial realm of you know what advertisements to local law enforcement is a voice recognition- specifically and the jail systems. Where we record all the telephone calls they go in and out of custody. And it does so you know they don't have an expectation of privacy and it does give a warning on the front and saying Hey this calls being recorded. Eccentrics address so- but what I technologies doing it transcribing that and this looking words so it's a key words or sentiment. Is looking for. No it are are we having previously having. Bowl indicators that there might be an assault. Or it's also picking up on maybe a motion where it's saying this person's depressed. And maybe they're having thoughts of being suicidal and then it would send an alert to somebody within custody. Saying Hey this person is X. means point some open perhaps you should have some type of targeted intervention plan with mental services or whatever it is I hueso. Kind of two different ways that is being used. One on the investigative I'm and kind of. Crime prevention side if you were. But then also on kind of more humanitarian- you know C. need if well for. People that are entrusted to us right so- so that's kind of where we're at- right now I mention that it currently the Joel system at least in my agency does not currently use of that couple voice recognition software but- every once in while we do have a company that tries to come by. And say Hey we had we can offer this- Bates it's a rather expensive. I'm a lot of these technologies are. So I'm but I will say that I think as we move into the future you know we look at. What is it that- a I. does for us and in an age where we have to do more with less- I think that it is a natural step to say yes we should be implementing these. Because we- the staff and you know it by. Double or triple the size of. My analytical team- to do crime analysis. I would happily take it- but if we can implement some of the smaller technological solutions hopefully that will kind of offset. That need for the increased I think so- I think we need to use it but I think. With that. I will say that I think. In the age of big data there's a lot of private companies out there that are collecting data and then it just typically it's been on the advertising or marketing side you're getting all that data and that's repackaged and then sold to the government or law enforcement for. An additional use right and it's that kind of a show use. Data set that for me is a little bit concerning. And I'll explain why so. Currently we have you know facial recognition we have license plate readers and we're using that and they're in different pockets if you will and you're trying to compare one data set to another. And I think in the future it. What were. Possibly looking at a it. Is a large company buying up despair data- and then aggregating it from different sources and then making a pattern. What I see in the future and I don't think it's that far off. Maybe five or ten years is you have- a company like it let's just say it's a grocery store or a regular department store. There is actively currently there's the technology where they track cellular devices within the stores to be able to figure out which I'll you're on what you like to spend money on where you're spending your within the store correct. I'm and it's don't for marketing purposes. If you then combine that with. A facial recognition for the CCTV camera and then maybe a license plate reader at the entrance to the store combining all of the- data sets. I mean you can get it really paranoid and think about- the Bluetooth sensor that measures your- tire pressure gauge or Mr tire pressure and sends it your car. So you have very distinct signals from different devices whether to do your your your cell phone or your- your vehicle your face. You know there's a lot of different data that's collected there if you aggregated in in total and then you multiply it over- you know either French doors or different that same store maybe it's a big change. How many times they go on it at a into this particular store and you get a really good indication of who your customer is and where they live. Exactly when they show up things like that and- I think it's really good for marking data. But I thought. I would caution that you could also use that if it's re packaged and sold to law enforcement say Hey or sold the loss prevention. And say. You know we've had this guy and he committed a theft. Last year and here's his entire history and here's all of his devices. So as he comes on the property now we have a license plate reader blue to censor something and saying Hey. This in that stone from us before is now approaching. This store now it was in a store and he has face recognition yes it's confirmed it's him and now he has a cell phone that. We know is. Associate. With right. So that type of. X. track something that could put together in the long run but- my question is. As we move along with that data I know on the law enforcement side we're struggling to hold all of our data and all of our evidence or digital evidence it's a huge undertaking but I think the but sector and their capabilities with that type of data in the cloud or or power they're stored in. That de is able to make those connections and when it's repackaged in given. I've to be. Transparency on sector is how it is they're collecting their data- and potentially how it is that the re packaging or selling are analyzing it. And there's a lot of. One of opportunity just to solve crimes there but there's also a lot of our opportunities. For it to be- yeah I was a misused but repurposed with out the understanding from the citizen. That didn't know that just going and going shopping was going to be this big Joel exhaust of the- that kind of makes sense so. I'm so going forward I think. A very large amounts and I think you guys have a very tough time to be able to balance take all these civil liberties and privacy rights and everything else on both the government side and- you know what's commercially available- and try to make it a little bit more transparent as to how it is that your data gets. Into the systems. Was it maybe you could. Or how can you avoid it- even just today I went in and something from a store as paying cash and asked me what your phone number. Well okay why we need a phone number to. Simple cash transaction right there is a that data goes and I don't know if there's enough education on the public side to be able to say Hey this is when your data gets into the system. And this is what it could eventually be used for. At you know it is it is what it. Unions of people knowing at you know who you are when you go into a store and knowing your history maybe it's easier to return an item if you get my phone number things like that but- ultimately I think we have to do to calm also look at the- privacy rights of individuals and say- you know. We're gonna end up in the long run so is before I absolutely think a eyes we needed- within law enforcement just because of the nature of the cases that we deal with. Us for crimes economic crime there's a huge amount of data that goes along with. And we need help just crunching it because we can't look at that data individually and make it that simple you know this person this because I saw on there. It is a- long. Bill that we have to sort through and- difficult. Manually having that. And to be able to do it. Is great but at the same time we need to do in that calculated measured way- so that we are taking those things into consideration so. I believe it would at that for now and in a little bit of yeah. Thank you. Answer any questions thank you. Sergeant don't you you've hit upon a number of different issues that are before us right now. Implicit bias issue privacy issues- law enforcement in terms of- refining our tools so that we do a better job of identifying. Of folks who are wrong doers a couple things one is it and I personally wrestle with the- distinction between data analysis. Which is so for example you get a bunch of phone numbers and you can you know sort of analyze the- hub in the spokes- versus artificial intelligence which- we'll get a better definition I'm sure later on. The day of where you have a system that actually. Makes decisions for you give that system problem and they come up with with a solution of the problem as opposed just gathering data- a couple questions though specific to your testimony. You'd mentioned this voice recognition technology of our are there any jurisdictions in California the that are using it for example in the jails. I'm sure that there are I believe I. R. I don't know which one off hand I'm sure there are. Jurisdictions using it- I could definitely. So I would be usable when you could let us know- I'd I'd be curious as to if G. if there's any jurisdiction using it. But the outcomes are- who the vendors are those those kinds of things because that is sort of the classic situation where you're giving. The system an issue identify for me those who are depressed and here you go and it comes up with. Some some responses to that you know the river clear I think that. We use it hi. I think Lara we need to be. Of exactly how the data is collected and how it's analyzed. Behind the model so a lot of the private companies you know come out next they want to sell your product and say yes it does this and it's this. A proprietary magic wand and then makes this suggestion this inference between. These two data points it's inferring this connection right based on this key word and that. It thinks that maybe you're depressed in custody right. I'm so having that human element to be able to understand exactly how the system works I think. Develop a lot more credibility really when you're looking at a system. As. Instigated lead or some type of. Action where you are deciding to do something- basically when we start talking about when we go to court. How is it that that system works we can't just blindly trust a machine to say yes you should do this and- knowing where the idea came from how it got crunched. And then understanding that logic and your will to put into words and ultimately into criminal prosecution is. It's cute the other issue that. Is of is before us and is of interest. Is this privacy. Concern. That you mention so for example I can see what the weather may be implicit bias. If a store identifies potential shoplifters by your virtue of where that person lives you can identify either by cellphone or by license plate you sell we're gonna we're gonna track this person because we think a person comes from this neighborhood is more likely to shoplift. That someone else. Honestly think it's based on where they live but I think it's based on their past history. With their relationship of knowing who lives in their stone beds that would be different but you could use it. It if you were. If you're being more simplistic by just. By just analyzing where the person lives and then making the leap. That that they may be more inclined which would be reflective of an implicit bias in my view would be. Inappropriate so anyway that that's that's the that's interesting issue that you've identified also be interested coordination and perhaps we can do this offline. But coordination between federal entities state and local entities that Beth is seems to always be a- continuing- both issue in tension between the various law enforcement agencies I can understand. Why folks are sometimes reluctant to share for example the confidential informants with others because they're concerned that. Press information Mike it. Eight either Edward Lear in it anyway so the so maybe we could do that conversation another point. Senate Chang. I have a ton of questions. My I concur with the good chairmen- with all the issues that you touched upon that's stop that we are grappling with in Sacramento currently- in fact when we're talking about- privacy you know- there was last year we passed the California consumer privacy acts of C. C. P. A.'s incredibly- yes right now it's- the forefront of a lot of- issues- the tech innovation caucus members we actually travel to DC. Was last week- to talk about the need for kind of an over arching- consumer privacy- law at the federal level- in California we're still working on some of the details because it's so complex this is a complex issue- but I am actually concerned now about these private companies you know these- data aggregators now trying to sell data to law enforcement and I feel like there needs to be greater transparency there because I don't know what kind of data there. Thanks. Sell you and I'm- I'll talk. Later to see what which Connie these are our doing that because that it. Is that we need to focus on transparency and how that data is gathered- and what kind of data. But I also wanted to get your thoughts on for example we just passed a law it was AB twelve fifteen which prohibits law enforcement from installing activating or using a biometric surveillance system. That was just codified and it has a three year sunset so I'm not sure if you have any thoughts on. This matter is that the same as the body worn camera official recognition yes okay- yes I might my thoughts on that is I think we'll be. I think it's a good step in the privacy rights of people but I also I kind of want to. Take it a step away from looking at you know we're we're at. To get ugly and I have these two hats I'm a really private person but at the same time I want to solve crime- and- I think there's like a balance that they could be made where. We're looking at. You know the ability to. Instantly identify or at least get a pretty good idea as to who somebody is. As a law enforcement officer talks to them. And I think there should be a clear distinction that we shouldn't be just randomly scanning everybody on a body worn camera however. I'm if we have somebody lawfully detained for investigation of a crime. We should be able to use- artificial intelligence to. By who that person is. Whether I take out my phone and I took a picture and I sent to the system. And it comes back as a yes it's compared to this booking photo we arrested him. You know a year ago and this is his photo we can compare that face to face. And get a positive ID- I know our department our department currently is. Spending a lot of money on mobile fingerprint recognition or mobile fingerprint identification systems- and I would say that probably the younger generation who wants information now- doesn't really want to wait for. Finger to come Bob. Just take a picture of me. I'll tell you who I am right- so I think there's a balance between. What it is that's expected what the community expects us to be able to do- I think. In Mike overall career I've talked to younger generations that. Have been really surprised as to what we're not able to do- you know they think that. It is a lot more capability than what we're actually able to do because we have. Different silos of information. So. Going back to the face recognition I mean I think. There could be a balance there. And it could be a need based on the level of detection that we have rather than. Maybe an outright I'm not saying no to buy metric solutions- deployed. If that makes sense yeah and then going long lines of transparency do you have any thoughts on. Or any suggestions for us on how how we can help maximize transparency. That's going to be huge yeah I think- you know in the future going you know you so we started the consumer privacy act or whatever was in California- I think it may be some. Very clear language you know if you go look at a company's- you know privacy policy or terms of service or things like that. It's usually five ten fifteen pages long and being able to read through all that really understanding what that means. Is difficult sometimes and I'm one of those guys that actually reads those before you click yes. Just to kind of see what it is that that I'm that I'm getting right am I getting myself into. There should be like almost. Also like a surgeon general's warning or something like that but a very clear message that says this bird this company will collect this information- if that makes sense and then as we go forward. Maybe just some public out reach gonna some. You know essays on you know how information is collected well more so from your department's perspective for. You know once. Once the a eyes fully implemented in terms transparency from a law enforcement perspective yeah I think you know from a law enforcement perspective I think it's easy for us to say. This is the data that we collect- and we look at it and in various ways- but being very clear as to how we collect data when we collected. And having policies in place as to when we purge that data. Is also very very pertinent and that comes back to you know when you look at the intelligence system and things like that we're looking at twenty eight CFR. With the collection retention and purging of information I think that is very a pretty good model. Thank you. One final question Mike. Co worker Mr honest points out that he opens his phone with facial recognition in a as to any of the four panelists I'm wondering if that information is been either offered to you or if you're where where that information is being sold to law enforcement or other other entities no I don't think it's been you know sold on the- art of use apple or Samsung or whatever I don't think that that is currently being sold I don't think that Mr. The our systems are set up it could be. However I would say that I. Probably unlock your phone by showing your phone to your face. So if you're looking at a government ability to be able to get into your device. Maybe using your faces and- the most secure way. Okay. Let me turn to judge not camara- judge Deborah I know you're you're all busy people I know you're particularly busy appreciate you being here today to offer your insights judge the floor is yours well thank you for inviting me to- explain what our core is doing with respect to artificial intelligence. Up let me. Firstly thank you were. So Bergen's etcetera Chang for. Allowing me to speak I'm very proud of our- court you're going to records were the most technologically advanced quartz- in the country. We have the support of judicial council as well as our chief justice Connie sick seals talking you whip who is a very much in support of using technology. To make our court system more efficient and fair. We have numerous projects in the tech technology field that we have. Going on and are pursuing let me just try to. Gloss over some of the rather mundane projects that we have and then go in more detail with respect to some once I consider much more interesting in terms of that. I require more computing power in an artificial intelligence. Some of the more a lesser projects or jury summons management- we are exploring using predictive analytics to determine if we can better manage your jury summons. Obviously we have to make sure that the this use of a I. does not apply yes our jury panel pools so that we have that we represent all. When we pull these soldiers in we're looking to analyze historical data in our case the U. lies juries. In you a I M. machine wanted to see if we can protect our need for jurors so we don't have to go. Pull as many jurors in for our jury trials. We are using. Automatic we're trying to use automatic redaction of documents are filed with the court we are very sensitive with the documents that may contain private information of individuals such as social security numbers and medical data of when they file it we were in the front. First courts to use efile. So what we have to use a certain level of. Of US screen to make sure that doctors should not contain private information that otherwise all of the public that can be used- for purposes that are appropriate. With respect to translation obviously in our court system we need certified translators to translate- in a criminal trial however. In our self help us centers we can use machine- translators- to help people that would come and who we have a legal problem. With three they were did your levels portals- we are working with. The various police departments to use. Electronic evidence with respect to traffic cases. With respect to- data exchange we are also working with- various other police agencies to exchange data. In order to better serve our public. Let me- point out of three super proud of projects I think there are very interesting and are more complex with respect the use of artificial intelligence first would be used to artificial intelligence for online dispute resolution. Other various court I've already use online dispute resolution of both in the civil and criminal contacts and you in Utah- there is a limited use of online dispute resolution and small claims cases. Of we are trying to. Interface with the Utah court in order to use some of their programs to- perhaps implement an all white dispute resolution. Our system with respect to civil this may require a certain number of change of our laws because it's understood that. Unless we make online speed resolution mandatory for let against it's probably not going to be used of very often. I'm I just be resolution is being used in the Michigan courts with respect to traffic citations it with the with. Very much success. That's something that we're looking into preliminarily. With respect to. Trying to have traffic cases resolved so people do not have to come into court and ultimately ever cases tried. Another use of artificial intelligence is something I thought of in- implementing our obligations under Senate bill fourteen thirty seven. Which is the abrogation of the felony murder rule with respect to fourteen thirty seven that requires the court to go through literally in Orange County thousands of cases. In order to determine whether. People who were convicted as in the success rate of felony murder roles are entitled to resend C. of these cases are extremely voluminous. And will require a considerable out of either staff timer G. full time to go through the records in order to determine whether the various elements of which entitles a defendant to be re sentence are satisfied. If we can develop. The artificial intelligence program which actually leans from the record from these luminous records the relevant documents that would assist. The Trier of fact the judge to determine whether those elements are present it so the defendant is entitled to resend seeing this could save our court hundreds of thousands of hours a legal researcher Clark hours in terms of. Looking through of these flumes transcripts. Our court system is presently going to be looking at S. B. ten of which is a pre trial release program- in lieu of bail that's- a controversial situation there is a- referendum out there the trying to repeal SP ten however. I at this point in time we are proceeding- with respect to our obligations to determine whether there are programs out there that will. Valley predict whether we can release defendants pre trial without harm to the public and with your high degree of certainty they will appear for a court appearance. I've looked at the some of those brands that are presently. Ben what data. Of those programs I believe are rather simplistic they provide a- one point for certain elements- at the V. pro. Privacy be the- Virginia tool. Has been validated for the Virginia population- there are various programs that are being implemented by the general counsel where. Grams are trying to be validated for population groups in California. I feel that- providing one point for each one of these elements is rather simplistic. If we can use. Artificial intelligence to give a more specific number of rather than one as opposed to one point three one point four depending on what the data. A was support- we could be much more precise in determining whether we should release. Of these defendants- pretrial conditions we should use yeah I'm releasing these defendants in a pre trial- arena yeah so we are required to do what presently under Senate bill and. I was told by a center Donora we're trying to develop some of these. Artificial intelligence programs- with- UC Irvine. A one of those programs- mistral is. Trying to assist the suburbs of litigants to you apply for protective order in a domestic violence case so we are- pursuing the situation where we are using- artificial intelligence to assist the- suburbs litigants to- actually apply. In a proper manner of four of those types of orders. So one. It's an exciting time of many of these programs are absent are at their but it's C. I would. Urge senators here that so who would have proper funding to the courts obviously so low can pursue- these many have a use which I think will make our- court rooms much more efficient. I think fair. Thank you thank you judge not Grenier I've had multiple discussions about how we can make the system to go still just system more efficient a couple questions you mentioned using artificial intelligence or some. System to. Dick I think predict in terms of the jury pool what what you may need to be more accurate is it are you currently using that system our or if I develop a program that does this all all these programs are out there in the C. right we are not presently using any of these right now these are projects that we are. Not trying to prioritize with respect to what's most important the court in terms of what we feel that we- would try to provide the most. Bang for our Buck so to speak you say we are you talking about just one case core you talking about the mystery of all courts I'm talking about they're going to record. We're up we have one of the largest the staff of technology of people. Problem for but once we develop these programs obviously we're not gonna keep them to ourselves we're gonna sure eleven song yes right we are new we form a trial court. Go ahead we a lot of these programs developed royally without the court's and we will share them with and that to the extent that- we've developed programs are beneficial to other courts around the state we certainly will. What if are there other jurisdictions outside of California that that have developed a methodology in terms of- calling the jury pool to be more efficient you know- not that I know of okay because of the wondering had they been challenged you said in Utah the using some sort of artificial intelligence system force for small claims. Online is pollution is it is there being involved there there are human beings involved the some online three resolution systems are rather Henry it's just a situation were offers. An answer given yeah that's not. The value of the case and try to suggest a- and number so to select case I mean I think these are it's one that we're do you know where those are being used. I. th. I think the- use the other countries to. I'm not here they've been used in the United States. I know that- we- in terms of insurance Kerry years they've been using these types of artificial intelligence predicted but analysis programs for years. Days so we'll of they know eggs. Degree how much a case is worth the based on certain factors they put into their programs and of this is what they allow their defense counsel offer. Obviously. That trash and trash out it's always good at sign. The fact is they put in. I hear tell the that there are programs that can for example after- council received vents cal's receives a complaint that can spit out of demurrer for example- up in it would seem that if that's the case that apps courts could look and see whether that demurrer is valid another words just look over the complaints if all the elements are. Properly pleaded is that being used anywhere no not really it. And again the. Color Jeff let the three bears the judge to make the ultimate decision there have been other. It's actually been cases of. Judges actually putting certain factors in their decision that ultimately gives a protective decision for them to make an I just basically allow the computer to make that decision and that was considered to be an ethical because the judge actually has to review the case and make sure that that case has specific. Factors that the court has considered the vessel with respect to the fourteen thirty seven situation I'm not proposing that ultimately we put all the factors into a court computer program- and ultimately help that okay recommendation it should be only used to get the ribbon information from these huge files. Of. Huge amount time can M. from the judge. Files all right a law clerk eight related legal research attorney so that the time that's involved in making that decision is very very much abbreviated. So there there's a new law effective January one two thousand twenty that provides the judges can are the parties can stipulate to- early exchange of information analogous to federal rule twenty six you may have heard of this judge not tomorrow yes I have a- and- a well reasoned rule I mean well thank you very much. And you your query that that would be something perhaps statewide that the administrative also courts may want to actually take a look at to see. Who's doing it what judges are suggesting it what court rooms is becoming more prevalent whether that has any impact on. Exploiting cases Ben and reducing discovery motions just a thought judge so yeah thanks for the suggestion I think it's very good one. Thank you Senate Chang. Thank you I'm I just want to go back to what you were saying about the traffic tickets was that. The A. R. A. I. being used and- well yeah again there's a. They're still human element in online dispute resolution at prickly when it's Bates when it's done in in Michigan what's happened is that certain citations are. Issued by the traffic officer and a proposed a- resolution of that. Is ultimately given up why a judge or a trick attorney with respect that usually at something much less than what you potentially could be. In terms of the fine. I and that that's offered to. Of the defendant of the person who made. The vial allegedly made violation and they have the opportunity to either accept that or eventually go to trial. So that's how in that's resolved quite a few of the various at least in Michigan. Citation they have their because but many times the offer made by the judge or the DNA is. Does not Derick choir a point being placed on that the defendant's record so what's the a large enticement for that defended the to accept that offer as opposed to go to trial and risk I having a point. Or two placed on there. There's a record so you mentioned there isn't a human element and there's definitely going to be human element in any type of technology that has been created. But the algorithm that is. Being constructed for this traffic taking I'm kind of curious about it because how would that look like so is it just not even. You don't even have to appear in court is that. Well a lot is the resolution basically is the ultimate goal is that people don't appear in court and they're given an offer. Us so that the they don't high enough so that they would. I believe that the it's better for them to take that off for us to post. Your court yet let's take an example of. It's a the speeding ticket this this is mission Jim because that's where where they have this. And it possibly can give you two points and it could. Be a fine of two three hundred dollars which is a lot less and would be in California but as we know. Ultimately the judge might look at the file and Mike. Might ultimately say that this person I'm a record of all prior violations. Of I will offer this person a traffic school hundred dollars no points and at that point in time that person can make a decision whether to contest that particular citation in court or take that offer. So that's how that would ultimately you work in that type of situation that the in California the fines are much higher- so we're gonna want to show up in court. Right so that's why I'm kind of curious as to what how that will help that's how it works. Okay interesting. Can I and I just want to comment that I completely agree with you that- assigning just one point- in terms of what Virginia's doing is a little bit too simplistic and yes there's like seven certain seven categories like white one point four and it it it just brought me is a very simplistic way to determine whether somebody should be- release pre trial or not I think we need something more precise. Absolutely thank you so much. Thank much. Up next we have a senator don senator slash dean's Lynch council done. Seller Dodd floors yours I thank you Mister chair- first let me extend my personal thank you along with my fellow panelists to- the chair to senator Chang your respective staff to the Senate staff- because I know as you indicated Mister chair- going on the road with the hearing is a logistic nightmare obviously for the great staff and then of course here again. Thank you to sergeant arms or here as well to whom I've known for a very very long time and it's great to see them here as well and now some of the greatest professionals I've ever encountered. I do have to extend a- an apology on behalf of the original designated- speaker for this role and implicit bias professor from UCLA and fortunately she- was. Taken down with the flu last night it sends her her sincere apologies for having to. Cancel and- I get the lucky task of stepping into her shoes. With great honor- I'm gonna take a slightly different approach to this is the issue of implicit bias you know particularly as it relates to- application law enforcement and judiciary- and take a very practical approach to it. But a little bit of background first- I come to it really in in two different roles- as special adviser to our dean song Richardson at the UCLA school of law. And as many of you know- she has been very public about. Jean you see I by- so one of the top twenty five plus schools in the country. As one of the first within the law academia bill breaks hi and in her words in the DNA. Of the law school on his Beth great honor to work with her. It in that process that is well under eight out. I'm also here- and the role I serve as chair of a national foundation. These projects. Your views projects mission is to eliminate child sexual exploitation and all of its forms on a global basis- and you'll see why that role that I share- is gonna come into play a relatively quickly here. Of so one it just share a little bit about what we've been doing in zero abuse because I'm gonna keep going back to it- as it relates to implicit and explicit biased in a I. applications we have been two years- it zero views project- and we own the intellectual property to it. To building in a I. platform that is focused on- identifying sexual predators of children. The prototype is built on what we refer to as institutional sexual abuse of children meaning abuse inside of an institution academia religious sports whatever the institution may be. And we've been working in collaboration with local national and international law enforcement agencies with respect to it we're two years in we're about to reach what's called minimum viable product with- which is years simplest form that it's ready to for deployment- literally in about two weeks- it's been a long process. I learned the hard way about a I. and billion a I. platforms through that process again and thank you to our outside company that's been building which is local. In Irvine techno says a tremendous- talent talent- that they brought to it- the premise of the platform simply is it observers C. externally observable. Behavioral patterns of an institution. Termin if the institution itself is hiding sexual predators of children inside. Focus is not on the predators and it's not on the survivors such victims it's on the behavior of the institution itself. If you can collect enough data on the externally observable behavioral patterns are and know what those patterns- means. You can then in essence on cover a cover up inside of eight institution. Our it's no surprise that there are some well known institution of struggled with this issue for decades- the Catholic Church of course the Boy Scouts and now we're beginning to see in academia. The end the Olympic- world- many sports programs unfortunately the list is very very long. This is the key investigative tool for long- intended for law enforcement on has no a I. application actually dictates anything we should all view output of any I. platform. Is simply a tool- some valuable information- that should lead to in. Other law enforcement contacts other. Traits investigation it's not a Beall and all conclusion but helpful in a variety of circumstances. Of the when that platform goes live you will not be made public- it will just be available to academic researchers law enforcement exedra- in the a prototype- it's eight an institution that has had this problem for a very long time there are. Thousands of known predators of children that have served in a institution and many that have not. Come to the light of day and our goal is to take the known- predators compared to the database on the rest of the individuals employed by that institution. And see if we can determine other predators- we think that number of other unknown predators to the public. Sadly is quite large consequences are huge- on average a sexual predator of children before here she is taken away from any access to a child. Usually has abused fifty or more kids before they're actually caught the numbers are. Staggering. Excuse me. So let me move into a practical examination of how bias Blissett and explicit get into any I. platform. It's not a new phenomenon we all know of the concern about biased in a I. applications- it's not a new phenomenon and- the tech world been aware of it from her for a very very long time. How to resolve it is a much more difficult issue- there's a lot of rhetoric around bias the issue biased in a I. applications- frayed at least in my humble view the rhetoric isn't necessarily on track. Every a I- application has buys in because it was created by humans and we all have it. So even though there's some that want to argue with that- C. a law enforcement platform- which deliberately dot bias against this community or that community. None of them were built that way- it's simply inherent if you understand. The build out of an A. I. platform isn't defended or make it right. But it's a very complicated question and I think for all of us particularly you as Sanders as policy makers. Of to ensure- understand for all the legislators that this is a complicated question despite all the rhetoric it sits. There in particular in the media space. I'm. I want to share something wish I could claim credit for this I can't- but probably drives the point home we all know what the cost of any I. platform is an algorithm or algorithms- and is often times said by many far more knowledgeable in the eyes and I. Is an algorithm is simply someone's opinion wrapped up in computer code. It's a great very laypersons definition it'll be the humor in there. But there's a lot of truth to it- because when I develop a premise for any I. platforms really my opinion. Is wrapped up by the tech folks in in computer jargon I can use that technical term- and if we keep that in mind when we think about bias in the I. that's a truism for almost every a I- application. That we see in the public or private sector- today including law enforcement the judiciary as as well to. The challenge however is for the average person on the street- many studies have shown. They trust the conclusion that came from a computer. More than they'll trust. An individual- perhaps the most common example is this is Google maps. We've all encountered a Google map direction that says go this way and you go. I just know that's wrong. But 99% of people will ignore their own experience and trust what the computer says. When in fact the computer can do harm to- and so you start to merge this opinion issue. Wrapped up in code with an inherent belief a computer is always right by the public. You've got a recipe for real challenges here because- implicit biases in every platform but if the public is going to assume the conclusion from a computer is right. We got a child. That's a big challenge there. So how does bias in- a I. applications come in to be. And this is where I want to get very practical- and- I'm going to generalize here so if we have any a I. experts in the audience of bristle at this but- it's a lay person's way of looking out the build out. Of an A. I. application. To see how black by it's gets introduced at many of the stages- and this makes it very difficult as- C. make yours. And how do we wrestle with issue when bias can be. Inserted into an application at many levels. We all have different definitions of a I. R. machine learning the tech industry doesn't like artificial intelligence they prefer machine learning for lots of good reasons- us Leyva folks. Are just comfortable with artificial intelligence which is probably more of a Hollywood label than it is anything else. But at its simplest form- is a I. machine learning is an algorithm that the tax patterns in big data sets. That's basically what it is in its in its simple and less funny way. But unfortunately it picks up patterns that yeah are in a database that a human created therefore there's lots of places that the- bias can can surface. We know it's a well known problem we know that a I. algorithms can perpetuate bias and justice whether it's in the hiring process many of us know the now infamous episode of the Amazon hiring process- in which they wanted to figure out. Who were the best candidates for application that would fit within Amazon and they based it upon- create a database of their past out of hiring. Of technical folks were very successful at Amazon. The unfortunate- problem was the they turned it off pretty quickly. The is it recommended hiring a lot of people who look like me and not very many people. Gender race or otherwise that didn't look like me. It step that was a pretty high profile on the situation Monning many- it's shown it you see it all it is C. the bias and retail applications security and law enforcement issues Cannella justice system. Every place a I. is use which is almost every industry- in society. Has a bias issue in it- I don't think anybody would stand before this committee and say I have any I. application that is zero bias. It doesn't exist. So to look at the build out of a I. platform you just from a labor of perspective is just three stages. It's what's called the framing the issue and requirements phase median what you want to accomplish. And what does the roadmap look like for us the technical folks in the subject matter experts what's the road back look like. To get to the end conclusion you want to cheat. On ours your abuse platform we wanted to identify unknown predators of children inside institutions that was a promise. What's the roadmap to get there on the institution we picked to build the platform on the prototype we needed subject matter experts about that institution. A I tech experts by themselves- they can create a lot of fun stuff but if we want to solve problems you need to join them with subject matter expertise. In the case of our presiding judge you need judicial experts to talk with the A. I. experts to build platform. Well in that for please call the requirement phrase- you can introduce bias quite unintended. And we've seen this lenders will have. Bill many different M. locations but let's ask what the mission is. If it's to increase profits. Or is it to increase repayment- percentages both depend upon how that lender will define credit worthiness. But if it's not a specific definition connected to that particular goal I just one increase profits of my company. You can enter to bias in simply defining a word in that requirement face. I'll parole risks there's a number of a I. applications that are trying to create. A I. analyses on the parole risk of someone who's about to be released. How do you define risks. Is that Rhys median likely to commit another crime. That wrist meaning likely to be calm dependent upon state resources for survival without committed a crime. If you define it only in one way but use it for different mission you're going to introduce by us and you haven't even started to build your database. Buyers can speak there- we had to be very specific on zero abuse pop form on what did we want to accomplish in their- folks thought when they help from. We presented to the U. N. twice on the platform. Were we trying to predict predators of that was the initial response in the answer is no. We don't do anything in our database- and our platform about the predator all about examining the institutional behavior. But if you mix the two in your requirement phase you're going to get by. The second phase in probably in most applications the most complicated phase a most difficult is building the database. That is a very challenging problem more challenging than we thought as we built this platform. On a particular institution where there's lots of publicly available data. But just that building of the database phase can introduce lots of different components of. Bias X. implicit or explicit. Of so let me give you a couple examples if your data is incomplete you're going to get some pretty biased outcomes let me create a hypothetical is loosely based on a real life situation. I'm a company that's trying to develop self driving cars. Well one of my challenges is tech team to train the car. To identify a pedestrian in a crosswalk. Pretty obvious risks for any driver obviously. And so to do that I go to my tech folks how are we going to train the card to identify pedestrian it to stop or to avoid that pedestrian that's in the crosswalk. Well in all likelihood of all of the tech folks who are designing the pedestrian issue in the build out look like me. Of what happens is the card gets trained to stop for a pedestrian that. Looks like me but unfortunately. And it really happened number two years ago. The tech folks didn't intend any bias at all but because of how they created the database and we're training the application it wasn't complete database it could not identify different gender than me a different race than me different heritages me. So I'm safe in the self I. in cars because I'm white male everybody else not so much. Obviously when they discovered the problem they had to go back to the drawing board but that's an incomplete data set. On a very critical issue that all of a sudden the technicians didn't mean to have a biased outcome. But it ended up by this outcome unfortunately. I we already talk real briefly about the Amazon situation predictive policing. Lots of rhetoric around a concept predicted Ripley scene nobody's really come up with much of a definition but we got the public debate over its got privacy implications bias implications all kinds of implications. We come up with if we agree upon the definition. But often times predicted please scene type platforms as they've been called are based on incomplete data. And if you have that predictably seen a- application may end up focusing on a particular community a particular type of person- and only focus on those and just perpetuate the bias and it's all started from an incomplete thought about the base. How you prepare the database. Now before you put the third phase which is putting the A. I. he's on to the database which is often times the most simplest process of the whole process interestingly enough- how you prepare it- in our- database for zero abuse project. We had to figure out what the flags were of that institution behavior that indicates that there is they're hiding a predator inside that institution. Well developed red flags- we found for the subject matter experts on that particular five platform. They had a list of red flags of how the institution handled folks inside that seem to indicate that they institutional concluded was predator of children. Of. Their own inherent bias in they'll- our it seemed to be an object of issue and it turned out to be a subject. We haven't even gotten to train. Platform yet- that these are just examples of how bias can does begin in the face to for most a I build out which is. Getting a workable database. Of I'm gonna use some technical terms and they're only ones because I'm not a technical guy- in our situation which is often times the case you have to take the raw data and person code. Meeting you you pretty to a format that's readable and workable in Exeter up. Of how you parsing code get introduce bias into your platform never intended- in our situation we found that- as we are perceiving coding would seem to be just. Addresses and street names and states and accept or something seemingly objective. Interestingly enough our own decisions about that part how to parsing code with the technical team ended up introducing some potential- bias into the process. And then of course your face three which is adding the A. I. application to it- that's where you train the A. I. aspect of it on what you want to accomplish because in a I. platform can't do anything on its own it has to be trained. What does though is it then moves from a kid a gardener. He we take twenty some odd years as humans to do that. And take a matter of days to go from kindergarten level to a PhD level on whatever the subject matter is. And then start connecting dots that the human mind can't see inside that database. Okay but now let's go to the issue how do you fix implicit bias is a well known problem- it's just the extent of how implicit bias gets into an A. I. application again whether it's judicial law enforcement. Private sector retail whatever the case may be it's all. The same. Of and again I'm ignoring those folks who deliberately designed by S. A. I. platform that's a whole different problem it's the- unintended. Bias that is really the challenge for us as a society from my perspective. There's that hotfixes obviously the Amazon hiring situation they all my gosh. We're not getting very many women- identified qualified applicants through this process so the immediately go to die okay we have to eliminate. Explicit gender works for example women applicant list. College activity women's swim team. Phone that thing got rejected by the email Amazon apple. Because there weren't very many women says swim team- folks wouldn't hire the past because everybody look like me. I'm overstating a little bit so Amazon doesn't get a little upset about that. They thought they fixed it but the A. I. application learn so fast and also picked up from the past database of applicants that there are certain words that tend to surface on application submitted by woman versus a man. Not the obvious word of a women's swimming team. But how things are phrased whether right or wrong it had concluded from the tap bass database that in fact. There is a subtle difference in language use on a resume and accept our so went to an implicit level and rejected the application. So it gets really complicated Amazon of course never intended to be biased in its it's a I. platform. But it happened both explicit and implicit so there's that hot fixes when you identify the bias in the source of the problem but that's just ad hoc after the fact- fact. The more the sing surface without getting caught ahead of time the more the public's faith. Goes down. And rightfully so. You can bill detection systems- most a I. platforms are built for performance not for bias detection. You can build in there are a I. platforms under development of can a I identify its own bias. Whether those will work we'll see- there are some who are debating whether in the requirements phase to we- require a platform in the it's its creators to define what absence of bias looks like. The problem so let me just finish with the following. It will say from a public policy perspective that's probably where most of the work is being done on how to deal with bias in the I. platforms. Could in law enforcement judicial which is so critical to function in society. I think we can be less concerned if I'm selling pet rocks and trying to figure out as a more through any I. application. But there is great. Being done on the policy lawn ethics surrounding bias in eight I but a lot of folks aren't aware of that- lot of it is on accountability issues responsibility issues ethical issues and etcetera and I'll- not leave it vague- the United Nations and several of its agencies. Are doing great international work in this area it's been an honor to work with us some of those agencies. From UNESCO- to the I. T. you know most people have no idea what that is that's the oldest of the agencies in the United Nations stands for international. Telecommunications union not union as we see the word union but- store clean- it's been around actually for over a hundred years but it became the first. U. N. agency they deal with all the technicians the policy. One we're working with his unit Cree that stands for the United Nations inter regional crime. And research Dodd- justice institute I get that right and maybe off just a little bit- they're doing great model policy work on- setting up. And via a barriers along the roadways as far as developing a I. in minimizing the risk of a I. number of trade associations that have many of the big tech companies are working on this. They're trying to find a fine balance. Many at the public level don't think that balance is a knife towards eliminating bias they're trying to find a nice balance of still makes for work. A I. apple turns but- at the same time Bates minimizes much as Italy's practically possible. A long ways to go unites these government of course is doing some states are doing. This this committee of course it is falls into that. Thank problem the two areas that are most focused on right now on the issue of bias in L. A. I. applications. Our transparency and explain ability those two words- and how do we require the president let me just interrupt you just for second we made certain representations of the panelists the time commitment almost finished out I want to make sure that that we're honoring those commitments so- for the three of you you're- certainly welcome to stay. But but it won't arrest you if you. Believe so. Anyway so thank you. Janet are right right so centered on thank you have reached our agents here but all the struck them not ten fifteen years. Okay a letter senator done tries that's a different story- my only last comment has are there is model policies- through many U. N. agencies or working on this. And others- that focus on dealing with implicit. Bias at least now as initial step. In focusing on transparency about bias and explain ability of the A. I. platform so that at least the public at large has an understanding and awareness. Of the bias issue- now obviously a lot of the creators of a I. platforms or worry about lecture property rates and all that kind of stuff because- I know the senator the chair is well aware of this. Gap in I. P. protection for a I. platforms is not easy. Because of how one defines a patentable idea. It has particularly difficult application in a I'd and. See a lot of businesses vendors exciter keeping their cards close because they know in many respects the can't get I. P. protection- but there's focus now transparency and explain ability with respect the- platforms as a way of. Least highlighting the bias so folks are aware and encouraging more work on the policy side tech side. And otherwise- and I'll just end with the following challenge I always the C. from our law enforcement community national state local. They they face a very big problem because they the and they realize that this is not not not new. In dealing with a I. nouns true in in past times the- all they know that some of the biggest spenders in developing a I. platform happen to be the drug cartels around the world- who aren't very interested in someone's constitutional rights or privacy or etcetera. Or biased in their application. And how does law enforcement effectively deal with something as severe and serious as drug cartels on a global basis who are spending billions on a I. development for their purposes. And still respond from an effective law enforcement perspective- but still having having to which everybody agrees including law enforcement. Under all the constitutional privacy perspex- protections that exist in this country- and it makes for a very very difficult tension- and when you're dealing with a criminal entities out there. They have lots of money to spend on a I don't care about bias don't care about privacy don't care about constitutional protections. And how do we respond effectively in today's society there's a way to do it- but it's a difficult- pathway and sadly- of for our policy makers in the state legislature and the governor's office. You guys have to make these hard decisions but I. N. was simply biased in a I. including law enforcement and judiciary. It it's introduced at multiple levels in every single application it doesn't mean that anybody is trying to do something inappropriate. It's just inherent into it because it's us humans to build them- and how do we as a society deal with those by that was a very difficult challenge as the tech world tried figured out. But you have to try to figure it out from a policy perspective all that all in their centers thank you. Thank you senator- and appreciate the tutorial and- recognize identifying what will the reasons we wanted to deal with. Artificial intelligence and how it relates the judiciary and law enforcement community and the issue of bias is because- this is an area can be most pernicious- if for example you happen to get additional advertising because somebody is used in. A I. algorithm to identify you as someone who is a potential purchaser of running shoes but the big deal. If your liberty is affected because of a certain bias. Whether it's in the judicial- brown or law enforcement that that is a big deals and so- I know you- as both professor as well as a foreign policy maker. Are concerned about a note I don't know if you've got any of your students here today my desire if I. Understand your so Cassie okay well thank you very much for being here but but I also understand you're gonna be working with the orange case peer court- judge not kommer a to deal with some of these issues and- I'm hoping you'll keep us abreast. Of how we can as policy makers make sure that that. The tools that we permit our our tools that are both effective but all so not- let's not biased in ways that. Are inappropriate so I want to thank you for that- thank you Senate check your questions. Maybe just some comments I want to thank you so much for your comprehensive in very thorough presentation I know all the getting your contact info and- talking offline but just. Just a brief comment about the self driving cars because- when I was in the same way I introduced a- legislation self. Driving cars but why would they need explicit data in order to prevent you know of an accident. Because of a person is crossing the street why when they use an algorithm just to figure out the mass. Rather than like. No gender and skin color I mean that that's just a little bizarre to me I would. When you're thinking about like people crossing the street I would. I would consider like the mass of even a dog right. And not so much like. Like the gender and race of a person crossing the street so I'm gonna. Use about that particular company in the algorithm but- again thank you so much for your presentation I really appreciate your expertise thank you senator it's- interesting on this self driving cars is. They their approach was to identify a mass mass that look like a pedestrian for example. Never intending- to introduce any sort of data or any other aspect that might indicate that there is. Some relevant difference between somebody who's male versus female or- inverse after American Exeter a- but very subtle it got introduced in the A. I. platform picked it up. And that came from. That's interesting. All right it in a moment we're going to have public Connie I'm gonna ask those who wish to comment to come to the microphone identify yourself and if you would Dodd. Where you reside- the purpose today's hearing is to focus on artificial intelligence and how it relates to law enforcement so I would ask in terms of. Providing us valuable input that we focus on that aspect- and- I'm going to right now I'm gonna live it folks to three minutes each. So if you are if you wish public comment if you would approach the Mike from we have not had folks fought hard so- if you come forward and- for yourself and where you live a great. Any public comment any with any persons wish to make. Lookup. Thank you so if you if you wish you could come forward there's not a long line so you'd come forward and common. Right right. Hi good afternoon my name is Jennifer Ross and I work with the ACLU of southern California here in Orange County I'm a resident of Huntington beach and I work in orange. You know as thank you for holding this hearing today as you well know the public deserves to feel safe. In their own neighborhoods and that's why public safety in this digital era. Must include extensive transparency community oversight and accountability. For a I. technologies that allow police to track and detain civilians as we go about our de daily lives. You know the committee spoke today on the need for public outreach when law enforcement employees surveillance technology. And often times particularly in this county we find our police departments and sheriff's departments purchasing a technology without the public without public knowledge or input- and- we really believe that the public has a right to know when local law enforcement and is considering the purchase of a I. technology. The secret use of a technology for as we know and as was spoken spoken on today of fuels discriminatory policing and provides recipe for abuse. Add technology can easily become a powerful tool for police misconduct. These technologies as we know can have the power to invade our private lives and create databases vulnerable to exploitation by local and federal government. Of for this reason we believe that community members must have extensive opportunity to provide input before any. Artificial intelligence technology is purchased by our local law enforcement agencies- and as a legislature we hope that. The you know are these committees and the legislature as a whole- does all that is in their power to prevent technology from being purchased without extensive public input and knowledge. I thank you very much for your time. Well anyone else wish to comment. But Sir go ahead my name is David radius and I live in Anaheim for Leslie seven years and I was invited by a friend of mine and I came here to learn you know and so. There's a lot of- concern as chairman- mention regarding bias and privacy and me being a man of. Color well I have some concerns on how that works you mentioned that. There was a el Salvadorian who photographed then if I was somebody does a smuggler and that help you catch that person. How accurate is this you know so if my face. Had a picture similar somebody a cartel. You know. Misidentification. How accurate is the your morning at. So can you help me out on this. Do I have to fear as a person you know with this the negative really mission positive. Things that it can do but is very negative examples that you guys experience. So Nancy certain. The no I appreciate appreciate your comment. The that if you direct your comments to us as policy makers what will take them aboard that and after everyone comments on- provide some response but- thank you thank you. Right others yes Sir. Hey good morning my name's Erik I'm with the AC you southern California and I'm in Anaheim resident have been all my life- and I think just a couple of comments I think one- predictive policing the sort of come up a lot and I think it's important to note that predictive policing predicts D. E. R. activity of police and that region right these trends the area as on the people are all based on who polices enforcing on not you know what I mean and so did that the concerned about the target retargeting of out of these communities I think it's- very important and has to be sort of. Dealt with that with the doubt see that it is making secondly we're already seen to the license plate reader point hi Julie solutions a private corporation is house in a lot of this data for a lot of law enforcement agencies right they were sharing that information with science writing so the unintended consequences of bringing in the private sector- to sell this data and to collect this data because law enforcement is unable to I think has we've already seen that issue right and how that plays out. Right there is no regulations on the way that these corporations have access to it the. Web of data sharing whereas the public's concern has always been to limit it and we've seen even ice on trial I. switches and trolley and the ACLU case the couple last month I want to say two months ago maybe- and that the ruling of that case- specific ice the trainers and databases. Which speaks to the fact that Rabin was that the status C. these databases are ill equipped and are unable to establish a just cause or probable cause even I'm in these cases where are the specific database issue was that US citizens who at some point were entered into this database- as and documented immigrants in the past Websense adjusted status has some sort of relief were being detained and does what it does for the plaintiffs right these are folks so there's already been sort of- really really widespread issues with the way that the status been collected. In the way that it's being used right and so just want to. As a cautionary sort of examples of the way that data has been used and it's- I totally agree with with- stone bridge point about. Right these are concerns of privacy right and so I think they do need to be dealt with very seriously thank you. Thank your- others. Anyone else wish to comment all right. If there's anyone else- indicia this gentleman- if you'd line up just so I can get a sense of how many folks want to comment that would be great. Go ahead. I have a morning my name is tomorrow but my love you sent the I'm currently a resident. Of Santana I'm also a source just as fellow Canadians resources fellowship- and pan PVC serve two terms on the C. Berkeley's police you commission. So I have previously worked on policies relating to a I. and surveillance technology. I think first and foremost what other folks have emphasized I think it's really important for the committee to be aware of income is events technologies. That are gonna be inputted into the police department I would like one recommendation is you know being allowed to host a community forum. Where the communities can allow to have input- I went to and what type of technologies that local enforcements want to your life in order to enforce and- M. police these communities- I think also employed in a conversation and important message. Is I feel like all of us should feel safe especially in our own neighborhoods. I think that's why public safety and that the Joel era must include transparency oversight and accountability for technology that allow police to track and detain us. As we go about our daily lives make false arrest interrogate us regarding our protective for some M. activities. And portray activists groups are for let's let's take the deportation machine- and as other folks have been seen in- transparency and accountability. Is there any. I think it's very important for me to have it. Community folks and surrounding cities in Orange County thank you. Thank you. Hello my name is Jordan Roger I am currently reside in Irvine and I am a member of senator done on a I. frontier course at UCLA school of law- one thing that I just really wanted to urge both of you to consider and all the senators and representatives of the state of California- kind of goes to one of the testimonies today about the protections of facial recognition and thumbprint recognition on phones- so judge west more of the Northern District. Of California actually has written an opinion and five that those should be protected under the Fifth Amendment and because it is a passcode and- the Supreme Court has ruled previously. Thought passcode are considered they can't be used against you went in a police interrogation or- for the like past thought I'm just because- that is self incriminating- and so I think that going forward we need to make sure that we are being protected by her Fifth Amendment. And she said that face ID and the fingerprinting. Is could be self incriminating and so. She blocked that for being used- but just the future policy makers need to make sure that we are being affected. Amendment thank you miss welcher our- his last comment go ahead ma'am hi good morning or good afternoon at this time many miss Kathy doubt I am also a student with senator done at U. C. I. law I'm our concern as process prospect of attorneys and you know this growing world of a I. Is at present a I. has a problem with implicit bias as we have touched upon in testimony today on the topic of transparency in I hope the Orange County Superior Court- shares with the community how they propose to reduce bias Dodd being fed into the court used a I. systems- and also how a I will be used to victory process more effective. Among the other processes being created this touches upon I believe the need for perhaps are more education to the public and there are members of the public are desperately compacted- and who also don't have access to fuller fully understanding the rights to publications that bring. I'm into this world so you just would hope the consent that thank you. Thank you what with you all. So for example just taking the last comment is that I could certainly see if you're trying to create a jury pool that you you want to make sure that you have jurors who can participate two or three week trial that would tend to indicate they want retirees they'll query whether by just by focusing on retirees you biasing the jury pool in an appropriate way I don't know the answer that but I do know that that that creates. Interesting dilemma court. Queen those who can put ten server. North thirty year old who's hourly employee may not may not be able to serve so or you want to respond Jackson J. sure say that the public to federal beer the presiding judge to because. Go ahead Klay involved in any type of considerations that we make with respect for jury pull. Up we already received a letter from Richard purpose you know just about a week ago- enquiring whether the court is going to make sure that- convicted felons who are now. A part of our jury pool as long as they're not probation are. Included in- the our summons and- but we- definitely will use up with the district attorney as well as- and- in any topic Senate races we- we make in terms of making sure that the- all is representative of the population as we are required to do but- thank you I and I think that's it that's that is illustrative of a difficult situation I. Retired to may have more time versus thirty. Least my view of a bias so heavily in favor of retirees but we say it's often we want pre qualified jurors- because it makes trees like a process much more. Hey can expedited but often times the public federal defense will object to that which is the right sure and we have to- exceed two well good luck with that judge I know you'll come up with the system that do it is fair about honoring it and we use that term- so the any. You could fit I not read the case. Fifth Amendment violation. Which is interesting burst forth ma'am but many of it so appreciate you bring that to our attention- the purchase of systems. A I. systems I hadn't thought about that but that that's another. Important point to is this the how we're going to provide that kind of transparency but still- not reveal certain investigative techniques that may alert bad guys and gals. As to where we're we're going that's that's another tension that that has been illustrated here today- and then sailed the sale that's why I was asking the question about. You know the collection of data so whether or you know somebody collects data. And then can sell it that is very very concerning to me and I think probably the other. Legislators as well so- I'm gonna turn the person tanker for her concluding comments and- an- agency in just a second but this is been more. Valuable for me thanks for step. Again the arms wrapped on this is incredibly important issue that were- as we will straighten the last hearing that we had we're way behind as a state in in in addressing it so let me let me turn it over to send a check thank you and again I want to think Mr men for convening. It is. Important to make an I am definitely going to be paying attention to the transparency aspects of the- the selling of data- and I already have some ideas in terms of. What we can do to ensure transparency especially of how they are collecting the data. And being sold and- you know what platforms are being used to collect data I think that- you know in and I'm just thinking out loud. Some people like only guy slings anything. But in terms of how the data is gathered who's selling it and- I think we need to have some type of the trail so that we can. I'm sure that it is being- gathered in nothing up way- but it is a very complex issue and- I'm hoping that Mister chair will be convening a more of these hearings because I think it's important to gather public input as well so. Thank you so much. M. with that we're going to conduct. Thank you so much specially to members of the panel Preciado thank you Sir. One thank reporter there yeah